{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9ERgBpbcMmB"
      },
      "source": [
        "# HW1: Frame-Level Speech Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLkH6GMGcWcE"
      },
      "source": [
        "In this homework, you will be working with MFCC data consisting of 27 features at each time step/frame. Your model should be able to recognize the phoneme occured in that frame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4vZbDmJvMp1"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwYu9sSUnSho",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bb86905-669f-4a3c-a517-f8529e4aa2a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.0 MB 29.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 184 kB 104.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 93.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 178 kB 103.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 177 kB 100.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 174 kB 106.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 173 kB 95.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 168 kB 110.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 168 kB 107.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 166 kB 97.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 166 kB 101.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 162 kB 101.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 162 kB 107.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 158 kB 107.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 105.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 108.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 109.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 106.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 99.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 104.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 92.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 156 kB 100.7 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install torchsummaryX wandb --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qI4qfx7tiBZt",
        "outputId": "ed7fd65f-28e1-497d-8050-439bf99cecd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device:  cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torchsummaryX import summary\n",
        "import sklearn\n",
        "import gc\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "import os\n",
        "import datetime\n",
        "import wandb\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device: \", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yBgXjKV1O0Z"
      },
      "outputs": [],
      "source": [
        "### If you are using colab, you can import google drive to save model checkpoints in a folder\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-9qE20hmCgQ"
      },
      "outputs": [],
      "source": [
        "### PHONEME LIST\n",
        "PHONEMES = [\n",
        "            '[SIL]',   'AA',    'AE',    'AH',    'AO',    'AW',    'AY',  \n",
        "            'B',     'CH',    'D',     'DH',    'EH',    'ER',    'EY',\n",
        "            'F',     'G',     'HH',    'IH',    'IY',    'JH',    'K',\n",
        "            'L',     'M',     'N',     'NG',    'OW',    'OY',    'P',\n",
        "            'R',     'S',     'SH',    'T',     'TH',    'UH',    'UW',\n",
        "            'V',     'W',     'Y',     'Z',     'ZH',    '[SOS]', '[EOS]']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIi0Big7vPa9"
      },
      "source": [
        "# Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBCbeRhixGM7"
      },
      "source": [
        "This section contains code that helps you install kaggle's API, creating kaggle.json with you username and API key details. Make sure to input those in the given code to ensure you can download data from the competition successfully."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPBUd7Cnl-Rx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d3c1ff9-809a-4ecf-874a-b11912834bfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kaggle==1.5.8\n",
            "  Downloading kaggle-1.5.8.tar.gz (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 7.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.8-py3-none-any.whl size=73274 sha256=08147c2596a485bf2241bc1f760a0366f3a65d52f7bbbc1439eb2038e18b589f\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/67/7b/a6d668747974998471d29b230e7221dd01330ac34faebe4af4\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.5.12\n",
            "    Uninstalling kaggle-1.5.12:\n",
            "      Successfully uninstalled kaggle-1.5.12\n",
            "Successfully installed kaggle-1.5.8\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle==1.5.8\n",
        "!mkdir /root/.kaggle\n",
        "\n",
        "with open(\"/root/.kaggle/kaggle.json\", \"w+\") as f:\n",
        "    f.write('{\"username\":\"nikhilcg2603\",\"key\":\"68c8ee5d31a123a0b0857ccf6e7c5752\"}') \n",
        "    # Put your kaggle username & key here\n",
        "\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "if2Somqfbje1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2060b9f-d22f-4908-d8a3-28425edc5ce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 11-785-s23-hw1p2.zip to /content\n",
            "100% 16.0G/16.0G [00:59<00:00, 321MB/s]\n",
            "100% 16.0G/16.0G [00:59<00:00, 287MB/s]\n"
          ]
        }
      ],
      "source": [
        "# commands to download data from kaggle\n",
        "\n",
        "!kaggle competitions download -c 11-785-s23-hw1p2\n",
        "!mkdir '/content/data'\n",
        "\n",
        "!unzip -qo '11-785-s23-hw1p2.zip' -d '/content/data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--Oe6mkwnykq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2b4f2c2-78d7-4f43-d26c-4000c7561194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting speechpy\n",
            "  Downloading speechpy-2.4-py2.py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from speechpy) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from speechpy) (1.7.3)\n",
            "Installing collected packages: speechpy\n",
            "Successfully installed speechpy-2.4\n"
          ]
        }
      ],
      "source": [
        "!pip install speechpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qpXlJbxnykr"
      },
      "outputs": [],
      "source": [
        "import speechpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vuzce0_TdcaR"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_7QgMbBdgPp"
      },
      "source": [
        "This section covers the dataset/dataloader class for speech data. You will have to spend time writing code to create this class successfully. We have given you a lot of comments guiding you on what code to write at each stage, from top to bottom of the class. Please try and take your time figuring this out, as it will immensely help in creating dataset/dataloader classes for future homeworks.\n",
        "\n",
        "Before running the following cells, please take some time to analyse the structure of data. Try loading a single MFCC and its transcipt, print out the shapes and print out the values. Do the transcripts look like phonemes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpLCvi3AJC5z"
      },
      "outputs": [],
      "source": [
        "# Dataset class to load train and validation data\n",
        "\n",
        "class AudioDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, root, phonemes = PHONEMES, context=0, offset=0, partition= \"dev-clean\", full_data= True): # Feel free to add more arguments\n",
        "\n",
        "        self.context    = context\n",
        "        self.phonemes   = phonemes\n",
        "        self.offset     = offset\n",
        "        # TODO: MFCC directory - use partition to acces train/dev directories from kaggle data using root\n",
        "        self.mfcc_dir       = (root+\"/\"+partition+\"/mfcc\")  \n",
        "        # TODO: Transcripts directory - use partition to acces train/dev directories from kaggle data using root\n",
        "        self.transcript_dir = (root+\"/\"+partition+\"/transcript\") \n",
        "\n",
        "        # TODO: List files in sefl.mfcc_dir using os.listdir in sorted order\n",
        "        mfcc_names          = sorted(os.listdir(self.mfcc_dir))\n",
        "        # TODO: List files in self.transcript_dir using os.listdir in sorted order\n",
        "        transcript_names    = sorted(os.listdir(self.transcript_dir)) \n",
        "\n",
        "        # Making sure that we have the same no. of mfcc and transcripts\n",
        "        assert len(mfcc_names) == len(transcript_names) \n",
        "\n",
        "        self.mfccs, self.transcripts = [], []\n",
        "\n",
        "        # TODO: Iterate through mfccs and transcripts\n",
        "        for i in range(len(mfcc_names)):\n",
        "        #   Load a single mfcc\n",
        "            mfcc        = np.load(self.mfcc_dir+\"/\"+mfcc_names[i])\n",
        "        #   Do Cepstral Normalization of mfcc (explained in writeup)\n",
        "            \n",
        "            mfcc = speechpy.processing.cmvn(mfcc)\n",
        "        #   Load the corresponding transcript\n",
        "            transcript  = np.load(self.transcript_dir+\"/\"+transcript_names[i]) # Remove [SOS] and [EOS] from the transcript \n",
        "            transcript = transcript[1:-1]\n",
        "            # (Is there an efficient way to do this without traversing through the transcript?)\n",
        "            # Note that SOS will always be in the starting and EOS at end, as the name suggests.\n",
        "        #   Append each mfcc to self.mfcc, transcript to self.transcript\n",
        "            self.mfccs.append(mfcc)\n",
        "            self.transcripts.append(transcript)        \n",
        "        \n",
        "        if full_data == True:\n",
        "          self.mfcc_dir1 = root+'/'+'dev-clean'+'/mfcc'\n",
        "          self.transcript_dir1 = root+'/'+'dev-clean'+'/transcript'\n",
        "          mfcc_names1 = os.listdir(self.mfcc_dir1)\n",
        "          transcript_names1 = os.listdir(self.transcript_dir1)  \n",
        "\n",
        "          for i in range(len(mfcc_names1)):\n",
        "            mfcc = np.load(self.mfcc_dir1+\"/\"+mfcc_names1[i])\n",
        "            mfcc = speechpy.processing.cmvn(mfcc)\n",
        "            transcript  = np.load(self.transcript_dir1+\"/\"+transcript_names1[i]) # Remove [SOS] and [EOS] from the transcript \n",
        "            transcript = transcript[1:-1]\n",
        "\n",
        "            self.mfccs.append(mfcc)\n",
        "            self.transcripts.append(transcript) \n",
        "\n",
        "          ####\n",
        "\n",
        "          self.mfcc_dir1 = root+'/'+'train-clean-360'+'/mfcc'\n",
        "          self.transcript_dir1 = root+'/'+'train-clean-360'+'/transcript'\n",
        "          mfcc_names1 = os.listdir(self.mfcc_dir1)\n",
        "          transcript_names1 = os.listdir(self.transcript_dir1)  \n",
        "\n",
        "          for i in range(len(mfcc_names1)):\n",
        "            mfcc = np.load(self.mfcc_dir1+\"/\"+mfcc_names1[i])\n",
        "            mfcc = speechpy.processing.cmvn(mfcc)\n",
        "            transcript  = np.load(self.transcript_dir1+\"/\"+transcript_names1[i]) # Remove [SOS] and [EOS] from the transcript \n",
        "            transcript = transcript[1:-1]\n",
        "\n",
        "            self.mfccs.append(mfcc)\n",
        "            self.transcripts.append(transcript) \n",
        "\n",
        "\n",
        "\n",
        "        # NOTE:\n",
        "        # Each mfcc is of shape T1 x 27, T2 x 27, ...\n",
        "        # Each transcript is of shape (T1+2) x 27, (T2+2) x 27 before removing [SOS] and [EOS]\n",
        "        \n",
        "        # TODO: Concatenate all mfccs in self.mfccs such that \n",
        "        # the final shape is T x 27 (Where T = T1 + T2 + ...) \n",
        "       \n",
        "        self.mfccs = np.concatenate(self.mfccs, axis=0)\n",
        "\n",
        "        # TODO: Concatenate all transcripts in self.transcripts such that \n",
        "        # the final shape is (T,) meaning, each time step has one phoneme output\n",
        "        self.transcripts    = np.concatenate(self.transcripts, axis=0, dtype = 'object')\n",
        "        # Hint: Use numpy to concatenate\n",
        "\n",
        "        # Length of the dataset is now the length of concatenated mfccs/transcripts\n",
        "        self.length = len(self.transcripts)\n",
        "\n",
        "        # Take some time to think about what we have done. \n",
        "        # self.mfcc is an array of the format (Frames x Features). \n",
        "        # Our goal is to recognize phonemes of each frame\n",
        "        # From hw0, you will be knowing what context is. \n",
        "        # We can introduce context by padding zeros on top and bottom of self.mfcc\n",
        "        self.mfccs = np.pad(self.mfccs, ((self.context, self.context), (0, 0)), 'constant', constant_values=0) # TODO\n",
        "\n",
        "        # The available phonemes in the transcript are of string data type\n",
        "        # But the neural network cannot predict strings as such. \n",
        "        # Hence, we map these phonemes to integers\n",
        "      \n",
        "        # TODO: Map the phonemes to their corresponding list indexes in self.phonemes\n",
        "        for i in range(len(self.transcripts)):\n",
        "            self.transcripts[i] = self.phonemes.index(self.transcripts[i]) \n",
        "        # Now, if an element in self.transcript is 0, it means that it is 'SIL' (as per the above example)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        \n",
        "        # TODO: Based on context and offset, return a frame at given index with context frames to the left, and right.\n",
        "       \n",
        "        #start_i = ind + self.offset - self.context\n",
        "        start_i = ind\n",
        "        #end_i = ind + self.offset + self.context + 1\n",
        "        end_i = ind + (2 * self.context) + 1\n",
        "        frames = self.mfccs[start_i:end_i]\n",
        "        # After slicing, you get an array of shape 2*context+1 x 27. But our MLP needs 1d data and not 2d.\n",
        "        \n",
        "        frames =  frames.flatten()# TODO: Flatten to get 1d data\n",
        "        frames      = torch.FloatTensor(frames) # Convert to tensors\n",
        "        \n",
        "        phonemes    = torch.tensor(self.transcripts[ind])       \n",
        "\n",
        "        return frames, phonemes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8KfVP39S6o7"
      },
      "outputs": [],
      "source": [
        "class AudioTestDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, phonemes = PHONEMES, context=0, offset=0, partition= \"dev-clean\"): # Feel free to add more arguments\n",
        "\n",
        "        self.context    = context\n",
        "        self.phonemes   = phonemes\n",
        "        self.offset     = offset\n",
        "        \n",
        "        self.mfcc_dir       = (root+\"/\"+partition+\"/mfcc\")  \n",
        "        mfcc_names          = sorted(os.listdir(self.mfcc_dir))\n",
        "        self.mfccs = []\n",
        "\n",
        "        for i in range(len(mfcc_names)):\n",
        "            mfcc        = np.load(self.mfcc_dir+\"/\"+mfcc_names[i])\n",
        "           \n",
        "\n",
        "            mfcc = speechpy.processing.cmvn(mfcc)\n",
        "            \n",
        "            self.mfccs.append(mfcc)\n",
        "\n",
        "        self.mfccs          = np.concatenate(self.mfccs, axis= 0)\n",
        "        self.length = len(self.mfccs) #This is to account the padding that we did for mfcc. This \n",
        "\n",
        "        self.mfccs = np.pad(self.mfccs, ((self.context, self.context), (0, 0)), 'constant', constant_values=0)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        \n",
        "        #start_i = ind + self.offset - self.context\n",
        "        start_i = ind\n",
        "        #end_i = ind + self.offset + self.context + 1\n",
        "        end_i = ind + (2 * self.context) + 1\n",
        "        frames = self.mfccs[start_i:end_i]\n",
        "        \n",
        "        \n",
        "        frames =  frames.flatten()\n",
        "        frames      = torch.FloatTensor(frames)\n",
        "        return frames\n",
        "    # TODO: Create a test dataset class similar to the previous class but you dont have transcripts for this\n",
        "    # Imp: Read the mfccs in sorted order, do NOT shuffle the data here or in your dataloader."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNacQ8bpt9nw"
      },
      "source": [
        "# Parameters Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WE7tsinAuLNy"
      },
      "source": [
        "Storing your parameters and hyperparameters in a single configuration dictionary makes it easier to keep track of them during each experiment. It can also be used with weights and biases to log your parameters for each experiment and keep track of them across multiple experiments. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmKwlFqgt_Zq"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    'epochs'        : 5,\n",
        "    'batch_size'    : 2048,\n",
        "    'context'       : 30,\n",
        "    'init_lr'       : 1e-3,\n",
        "    'architecture'  : 'double cylinder',\n",
        "    'dropout'       : 0.15,\n",
        "    'step_size'     : 1,\n",
        "    'gamma'         : 0.05,\n",
        "    'weight_decay'  : 1e-2,\n",
        "    'T_max'         : 10,\n",
        "    'eta_min'       : 0,\n",
        "    'factor'        : 0.1 \n",
        "    # Add more as you need them - e.g dropout values, weight decay, scheduler parameters\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mlwaKlDt_2c"
      },
      "source": [
        "# Create Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xi7V8x8W9z4"
      },
      "outputs": [],
      "source": [
        "root = \"/content/data/11-785-s23-hw1p2\"\n",
        "#TODO: Create a dataset object using the AudioDataset class for the training data \n",
        "train_data = AudioDataset(root,PHONEMES,context= config['context'],offset=0, partition=\"train-clean-100\", full_data= True) \n",
        "\n",
        "# TODO: Create a dataset object using the AudioDataset class for the validation data \n",
        "val_data = AudioDataset(root,PHONEMES,context= config['context'], offset=0, partition=\"dev-clean\", full_data= False) \n",
        "\n",
        "# TODO: Create a dataset object using the AudioTestDataset class for the test data \n",
        "test_data = AudioTestDataset(root,PHONEMES,context= config['context'],offset=0, partition= \"test-clean\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mzoYfTKu14s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c363e318-480a-4f14-8b29-fc32c470dcf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size     :  2048\n",
            "Context        :  45\n",
            "Input size     :  2457\n",
            "Output symbols :  42\n",
            "Train dataset samples = 168473356, batches = 82263\n",
            "Validation dataset samples = 1928204, batches = 942\n",
            "Test dataset samples = 1934138, batches = 945\n"
          ]
        }
      ],
      "source": [
        "# Define dataloaders for train, val and test datasets\n",
        "# Dataloaders will yield a batch of frames and phonemes of given batch_size at every iteration\n",
        "# We shuffle train dataloader but not val & test dataloader. Why?\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = train_data, \n",
        "    num_workers = 4, #4\n",
        "    batch_size  = config['batch_size'], \n",
        "    pin_memory  = True,\n",
        "    shuffle     = True\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = val_data, \n",
        "    num_workers = 2, #2\n",
        "    batch_size  = config['batch_size'],\n",
        "    pin_memory  = True,\n",
        "    shuffle     = False\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = test_data, \n",
        "    num_workers = 2, #2\n",
        "    batch_size  = config['batch_size'], \n",
        "    pin_memory  = True, \n",
        "    shuffle     = False\n",
        ")\n",
        "\n",
        "\n",
        "print(\"Batch size     : \", config['batch_size'])\n",
        "print(\"Context        : \", config['context'])\n",
        "print(\"Input size     : \", (2*config['context']+1)*27)\n",
        "print(\"Output symbols : \", len(PHONEMES))\n",
        "\n",
        "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
        "print(\"Validation dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\n",
        "print(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-GV3UvgLSoF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aad005b-2835-435f-e36a-5f10eede964c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2048, 2457]) torch.Size([2048])\n"
          ]
        }
      ],
      "source": [
        "# Testing code to check if your data loaders are working\n",
        "for i, data in enumerate(train_loader):\n",
        "    frames, phoneme = data\n",
        "    print(frames.shape, phoneme.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nxjwve20JRJ2"
      },
      "source": [
        "# Network Architecture\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NJzT-mRw6iy"
      },
      "source": [
        "This section defines your network architecture for the homework. We have given you a sample architecture that can easily clear the very low cutoff for the early submission deadline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvcpontXQq9j"
      },
      "outputs": [],
      "source": [
        "# This architecture will make you cross the very low cutoff\n",
        "# However, you need to run a lot of experiments to cross the medium or high cutoff\n",
        "class Network(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, output_size):\n",
        "\n",
        "        super(Network, self).__init__()\n",
        "        # # self.model.name = \"Cylinder 2048\"\n",
        "        # self.model = torch.nn.Sequential(\n",
        "        #     torch.nn.Linear(input_size, 2048),\n",
        "        #     torch.nn.BatchNorm1d(2048),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(2048,2048),\n",
        "        #     torch.nn.BatchNorm1d(2048),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(2048,2048),\n",
        "        #     torch.nn.BatchNorm1d(2048),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(2048,2048),\n",
        "        #     torch.nn.BatchNorm1d(2048),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(2048,2048),\n",
        "        #     torch.nn.BatchNorm1d(2048),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(2048,40),\n",
        "        #     torch.nn.BatchNorm1d(40),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(40, output_size) #Change to 40,out if using the previous layer\n",
        "        # )      \n",
        "\n",
        "        # # self.model.name = \"Cylinder 1024\"\n",
        "        # self.model = torch.nn.Sequential(\n",
        "        #     torch.nn.Linear(input_size, 1024),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1024,1024),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1024,1024),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1024,1024),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1024,1024),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1024,1024),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1024,1024),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1024,1024),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1024,1024),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1024,1024),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1024,1024),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1024,1024),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1024,1024),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1024,1024),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1024,1024),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1024,1024),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1024,1024),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1024,1024),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     # torch.nn.Dropout(p = config['dropout']),\n",
        "        #     # torch.nn.Linear(2048,40),\n",
        "        #     # torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1024, output_size) #Change to 40,out if using the previous layer\n",
        "        # )      \n",
        "\n",
        "        # # self.model.name = \"ZigZag 2048\"\n",
        "        # self.model = torch.nn.Sequential(\n",
        "        #     torch.nn.Linear(input_size, 2048),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(2048,1024),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1024,2048),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(2048,1024),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1024,2048),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(2048,1024),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1024,2048),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(2048,1024),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     # torch.nn.Dropout(p = config['dropout']),\n",
        "        #     # torch.nn.Linear(2048,40),\n",
        "        #     # torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1024, output_size) #Change to 40,out if using the previous layer\n",
        "        # )\n",
        "\n",
        "         # self.model.name = \"zipper 2000\"\n",
        "        self.model = torch.nn.Sequential(\n",
        "            torch.nn.Linear(input_size, 1450),\n",
        "            torch.nn.BatchNorm1d(1450),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Dropout(p = config['dropout']),\n",
        "            torch.nn.Linear(1450,2000),\n",
        "            torch.nn.BatchNorm1d(2000),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Dropout(p = config['dropout']),\n",
        "            torch.nn.Linear(2000,1450),\n",
        "            torch.nn.BatchNorm1d(1450),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Dropout(p = config['dropout']),\n",
        "            torch.nn.Linear(1450,2000),\n",
        "            torch.nn.BatchNorm1d(2000),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Dropout(p = config['dropout']),\n",
        "            torch.nn.Linear(2000,1450),\n",
        "            torch.nn.BatchNorm1d(1450),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Dropout(p = config['dropout']),\n",
        "            torch.nn.Linear(1450,2000),\n",
        "            torch.nn.BatchNorm1d(2000),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Dropout(p = config['dropout']),\n",
        "            torch.nn.Linear(2000,1450),\n",
        "            torch.nn.BatchNorm1d(1450),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Dropout(p = config['dropout']),\n",
        "            torch.nn.Linear(1450,50),\n",
        "            torch.nn.BatchNorm1d(50),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Dropout(p = config['dropout']),\n",
        "            torch.nn.Linear(50, output_size) #Change to 40,out if using the previous layer\n",
        "        )      \n",
        "\n",
        "        #  # self.model.name = \"hour glass 4096\"\n",
        "        # self.model = torch.nn.Sequential(\n",
        "        #     torch.nn.Linear(input_size, 2048),\n",
        "        #     torch.nn.BatchNorm1d(2048),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(2048,1024),\n",
        "        #     torch.nn.BatchNorm1d(1024),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1024,512),\n",
        "        #     torch.nn.BatchNorm1d(512),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(512,256),\n",
        "        #     torch.nn.BatchNorm1d(256),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(256,512),\n",
        "        #     torch.nn.BatchNorm1d(512),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(512,1024),\n",
        "        #     torch.nn.BatchNorm1d(1024),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1024,2048),\n",
        "        #     torch.nn.BatchNorm1d(2048),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(2048, output_size) #Change to 40,out if using the previous layer\n",
        "        # )    \n",
        "\n",
        "        # # self.model.name = \"Double Cylinder 1500\"\n",
        "        # self.model = torch.nn.Sequential(\n",
        "        #     torch.nn.Linear(input_size, 1500),\n",
        "        #     torch.nn.BatchNorm1d(1500),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1500,1500),\n",
        "        #     torch.nn.BatchNorm1d(1500),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     # torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1500,1500),\n",
        "        #     torch.nn.BatchNorm1d(1500),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1500,1500),\n",
        "        #     torch.nn.BatchNorm1d(1500),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     # torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1500,1500),\n",
        "        #     torch.nn.BatchNorm1d(1500),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1500,1500),\n",
        "        #     torch.nn.BatchNorm1d(1500),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     # torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1500,750),\n",
        "        #     torch.nn.BatchNorm1d(750),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(750,750),\n",
        "        #     torch.nn.BatchNorm1d(750),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(750,750),\n",
        "        #     torch.nn.BatchNorm1d(750),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(750,750),\n",
        "        #     torch.nn.BatchNorm1d(750),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(750,750),\n",
        "        #     torch.nn.BatchNorm1d(750),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(750,750),\n",
        "        #     torch.nn.BatchNorm1d(750),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(750,750),\n",
        "        #     torch.nn.BatchNorm1d(750),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(750,656),\n",
        "        #     torch.nn.BatchNorm1d(656),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(656, output_size) #Change to 40,out if using the previous layer\n",
        "        # )        \n",
        "\n",
        "        # # self.model.name = \"Cylinder 1500\"\n",
        "        # self.model = torch.nn.Sequential(\n",
        "        #     torch.nn.Linear(input_size, 1500),\n",
        "        #     torch.nn.BatchNorm1d(1500),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1500,1500),\n",
        "        #     torch.nn.BatchNorm1d(1500),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1500,1500),\n",
        "        #     torch.nn.BatchNorm1d(1500),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1500,1500),\n",
        "        #     torch.nn.BatchNorm1d(1500),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1500,1500),\n",
        "        #     torch.nn.BatchNorm1d(1500),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1500,1500),\n",
        "        #     torch.nn.BatchNorm1d(1500),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1500,1500),\n",
        "        #     torch.nn.BatchNorm1d(1500),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1500,1500),\n",
        "        #     torch.nn.BatchNorm1d(1500),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1500,1350),\n",
        "        #     torch.nn.BatchNorm1d(1350),\n",
        "        #     torch.nn.GELU(),\n",
        "        #     torch.nn.Dropout(p = config['dropout']),\n",
        "        #     torch.nn.Linear(1350, output_size) #Change to 40,out if using the previous layer\n",
        "        # )      \n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.model(x)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HejoSXe3vMVU"
      },
      "source": [
        "# Define Model, Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize(model):\n",
        "  if type(model)==torch.nn.Linear:\n",
        "    torch.nn.init.xavier_normal(model.weight,gain=1.0)\n",
        "    # torch.nn.init.kaiming_normal_(model.weight, mode= 'fan_in')"
      ],
      "metadata": {
        "id": "Z05wO5Iu1JeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAhGBH7-xxth"
      },
      "source": [
        "Here we define the model, loss function, optimizer and optionally a learning rate scheduler. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qtrEM1ZvLje",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fc665f0b-dec9-4a5b-cbba-80054cb0c51f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================\n",
            "                         Kernel Shape  Output Shape    Params Mult-Adds\n",
            "Layer                                                                  \n",
            "0_model.Linear_0         [2457, 1500]  [2048, 1500]    3.687M   3.6855M\n",
            "1_model.BatchNorm1d_1          [1500]  [2048, 1500]      3.0k      1.5k\n",
            "2_model.GELU_2                      -  [2048, 1500]         -         -\n",
            "3_model.Dropout_3                   -  [2048, 1500]         -         -\n",
            "4_model.Linear_4         [1500, 1500]  [2048, 1500]   2.2515M     2.25M\n",
            "5_model.BatchNorm1d_5          [1500]  [2048, 1500]      3.0k      1.5k\n",
            "6_model.GELU_6                      -  [2048, 1500]         -         -\n",
            "7_model.Linear_7         [1500, 1500]  [2048, 1500]   2.2515M     2.25M\n",
            "8_model.BatchNorm1d_8          [1500]  [2048, 1500]      3.0k      1.5k\n",
            "9_model.GELU_9                      -  [2048, 1500]         -         -\n",
            "10_model.Dropout_10                 -  [2048, 1500]         -         -\n",
            "11_model.Linear_11       [1500, 1500]  [2048, 1500]   2.2515M     2.25M\n",
            "12_model.BatchNorm1d_12        [1500]  [2048, 1500]      3.0k      1.5k\n",
            "13_model.GELU_13                    -  [2048, 1500]         -         -\n",
            "14_model.Linear_14       [1500, 1500]  [2048, 1500]   2.2515M     2.25M\n",
            "15_model.BatchNorm1d_15        [1500]  [2048, 1500]      3.0k      1.5k\n",
            "16_model.GELU_16                    -  [2048, 1500]         -         -\n",
            "17_model.Dropout_17                 -  [2048, 1500]         -         -\n",
            "18_model.Linear_18       [1500, 1500]  [2048, 1500]   2.2515M     2.25M\n",
            "19_model.BatchNorm1d_19        [1500]  [2048, 1500]      3.0k      1.5k\n",
            "20_model.GELU_20                    -  [2048, 1500]         -         -\n",
            "21_model.Linear_21        [1500, 750]   [2048, 750]  1.12575M    1.125M\n",
            "22_model.BatchNorm1d_22         [750]   [2048, 750]      1.5k     750.0\n",
            "23_model.GELU_23                    -   [2048, 750]         -         -\n",
            "24_model.Dropout_24                 -   [2048, 750]         -         -\n",
            "25_model.Linear_25         [750, 750]   [2048, 750]   563.25k    562.5k\n",
            "26_model.BatchNorm1d_26         [750]   [2048, 750]      1.5k     750.0\n",
            "27_model.GELU_27                    -   [2048, 750]         -         -\n",
            "28_model.Dropout_28                 -   [2048, 750]         -         -\n",
            "29_model.Linear_29         [750, 750]   [2048, 750]   563.25k    562.5k\n",
            "30_model.BatchNorm1d_30         [750]   [2048, 750]      1.5k     750.0\n",
            "31_model.GELU_31                    -   [2048, 750]         -         -\n",
            "32_model.Dropout_32                 -   [2048, 750]         -         -\n",
            "33_model.Linear_33         [750, 750]   [2048, 750]   563.25k    562.5k\n",
            "34_model.BatchNorm1d_34         [750]   [2048, 750]      1.5k     750.0\n",
            "35_model.GELU_35                    -   [2048, 750]         -         -\n",
            "36_model.Dropout_36                 -   [2048, 750]         -         -\n",
            "37_model.Linear_37         [750, 750]   [2048, 750]   563.25k    562.5k\n",
            "38_model.BatchNorm1d_38         [750]   [2048, 750]      1.5k     750.0\n",
            "39_model.GELU_39                    -   [2048, 750]         -         -\n",
            "40_model.Dropout_40                 -   [2048, 750]         -         -\n",
            "41_model.Linear_41         [750, 750]   [2048, 750]   563.25k    562.5k\n",
            "42_model.BatchNorm1d_42         [750]   [2048, 750]      1.5k     750.0\n",
            "43_model.GELU_43                    -   [2048, 750]         -         -\n",
            "44_model.Dropout_44                 -   [2048, 750]         -         -\n",
            "45_model.Linear_45         [750, 750]   [2048, 750]   563.25k    562.5k\n",
            "46_model.BatchNorm1d_46         [750]   [2048, 750]      1.5k     750.0\n",
            "47_model.GELU_47                    -   [2048, 750]         -         -\n",
            "48_model.Dropout_48                 -   [2048, 750]         -         -\n",
            "49_model.Linear_49         [750, 656]   [2048, 656]  492.656k    492.0k\n",
            "50_model.BatchNorm1d_50         [656]   [2048, 656]    1.312k     656.0\n",
            "51_model.GELU_51                    -   [2048, 656]         -         -\n",
            "52_model.Dropout_52                 -   [2048, 656]         -         -\n",
            "53_model.Linear_53          [656, 42]    [2048, 42]   27.594k   27.552k\n",
            "-------------------------------------------------------------------------\n",
            "                          Totals\n",
            "Total params          19.999812M\n",
            "Trainable params      19.999812M\n",
            "Non-trainable params         0.0\n",
            "Mult-Adds             19.969958M\n",
            "=========================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchsummaryX/torchsummaryX.py:101: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  df_sum = df.sum()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         Kernel Shape  Output Shape     Params  Mult-Adds\n",
              "Layer                                                                    \n",
              "0_model.Linear_0         [2457, 1500]  [2048, 1500]  3687000.0  3685500.0\n",
              "1_model.BatchNorm1d_1          [1500]  [2048, 1500]     3000.0     1500.0\n",
              "2_model.GELU_2                      -  [2048, 1500]        NaN        NaN\n",
              "3_model.Dropout_3                   -  [2048, 1500]        NaN        NaN\n",
              "4_model.Linear_4         [1500, 1500]  [2048, 1500]  2251500.0  2250000.0\n",
              "5_model.BatchNorm1d_5          [1500]  [2048, 1500]     3000.0     1500.0\n",
              "6_model.GELU_6                      -  [2048, 1500]        NaN        NaN\n",
              "7_model.Linear_7         [1500, 1500]  [2048, 1500]  2251500.0  2250000.0\n",
              "8_model.BatchNorm1d_8          [1500]  [2048, 1500]     3000.0     1500.0\n",
              "9_model.GELU_9                      -  [2048, 1500]        NaN        NaN\n",
              "10_model.Dropout_10                 -  [2048, 1500]        NaN        NaN\n",
              "11_model.Linear_11       [1500, 1500]  [2048, 1500]  2251500.0  2250000.0\n",
              "12_model.BatchNorm1d_12        [1500]  [2048, 1500]     3000.0     1500.0\n",
              "13_model.GELU_13                    -  [2048, 1500]        NaN        NaN\n",
              "14_model.Linear_14       [1500, 1500]  [2048, 1500]  2251500.0  2250000.0\n",
              "15_model.BatchNorm1d_15        [1500]  [2048, 1500]     3000.0     1500.0\n",
              "16_model.GELU_16                    -  [2048, 1500]        NaN        NaN\n",
              "17_model.Dropout_17                 -  [2048, 1500]        NaN        NaN\n",
              "18_model.Linear_18       [1500, 1500]  [2048, 1500]  2251500.0  2250000.0\n",
              "19_model.BatchNorm1d_19        [1500]  [2048, 1500]     3000.0     1500.0\n",
              "20_model.GELU_20                    -  [2048, 1500]        NaN        NaN\n",
              "21_model.Linear_21        [1500, 750]   [2048, 750]  1125750.0  1125000.0\n",
              "22_model.BatchNorm1d_22         [750]   [2048, 750]     1500.0      750.0\n",
              "23_model.GELU_23                    -   [2048, 750]        NaN        NaN\n",
              "24_model.Dropout_24                 -   [2048, 750]        NaN        NaN\n",
              "25_model.Linear_25         [750, 750]   [2048, 750]   563250.0   562500.0\n",
              "26_model.BatchNorm1d_26         [750]   [2048, 750]     1500.0      750.0\n",
              "27_model.GELU_27                    -   [2048, 750]        NaN        NaN\n",
              "28_model.Dropout_28                 -   [2048, 750]        NaN        NaN\n",
              "29_model.Linear_29         [750, 750]   [2048, 750]   563250.0   562500.0\n",
              "30_model.BatchNorm1d_30         [750]   [2048, 750]     1500.0      750.0\n",
              "31_model.GELU_31                    -   [2048, 750]        NaN        NaN\n",
              "32_model.Dropout_32                 -   [2048, 750]        NaN        NaN\n",
              "33_model.Linear_33         [750, 750]   [2048, 750]   563250.0   562500.0\n",
              "34_model.BatchNorm1d_34         [750]   [2048, 750]     1500.0      750.0\n",
              "35_model.GELU_35                    -   [2048, 750]        NaN        NaN\n",
              "36_model.Dropout_36                 -   [2048, 750]        NaN        NaN\n",
              "37_model.Linear_37         [750, 750]   [2048, 750]   563250.0   562500.0\n",
              "38_model.BatchNorm1d_38         [750]   [2048, 750]     1500.0      750.0\n",
              "39_model.GELU_39                    -   [2048, 750]        NaN        NaN\n",
              "40_model.Dropout_40                 -   [2048, 750]        NaN        NaN\n",
              "41_model.Linear_41         [750, 750]   [2048, 750]   563250.0   562500.0\n",
              "42_model.BatchNorm1d_42         [750]   [2048, 750]     1500.0      750.0\n",
              "43_model.GELU_43                    -   [2048, 750]        NaN        NaN\n",
              "44_model.Dropout_44                 -   [2048, 750]        NaN        NaN\n",
              "45_model.Linear_45         [750, 750]   [2048, 750]   563250.0   562500.0\n",
              "46_model.BatchNorm1d_46         [750]   [2048, 750]     1500.0      750.0\n",
              "47_model.GELU_47                    -   [2048, 750]        NaN        NaN\n",
              "48_model.Dropout_48                 -   [2048, 750]        NaN        NaN\n",
              "49_model.Linear_49         [750, 656]   [2048, 656]   492656.0   492000.0\n",
              "50_model.BatchNorm1d_50         [656]   [2048, 656]     1312.0      656.0\n",
              "51_model.GELU_51                    -   [2048, 656]        NaN        NaN\n",
              "52_model.Dropout_52                 -   [2048, 656]        NaN        NaN\n",
              "53_model.Linear_53          [656, 42]    [2048, 42]    27594.0    27552.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b409e858-6a28-47df-8592-c2874fa9968a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Kernel Shape</th>\n",
              "      <th>Output Shape</th>\n",
              "      <th>Params</th>\n",
              "      <th>Mult-Adds</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Layer</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_model.Linear_0</th>\n",
              "      <td>[2457, 1500]</td>\n",
              "      <td>[2048, 1500]</td>\n",
              "      <td>3687000.0</td>\n",
              "      <td>3685500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_model.BatchNorm1d_1</th>\n",
              "      <td>[1500]</td>\n",
              "      <td>[2048, 1500]</td>\n",
              "      <td>3000.0</td>\n",
              "      <td>1500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_model.GELU_2</th>\n",
              "      <td>-</td>\n",
              "      <td>[2048, 1500]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_model.Dropout_3</th>\n",
              "      <td>-</td>\n",
              "      <td>[2048, 1500]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_model.Linear_4</th>\n",
              "      <td>[1500, 1500]</td>\n",
              "      <td>[2048, 1500]</td>\n",
              "      <td>2251500.0</td>\n",
              "      <td>2250000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_model.BatchNorm1d_5</th>\n",
              "      <td>[1500]</td>\n",
              "      <td>[2048, 1500]</td>\n",
              "      <td>3000.0</td>\n",
              "      <td>1500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_model.GELU_6</th>\n",
              "      <td>-</td>\n",
              "      <td>[2048, 1500]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_model.Linear_7</th>\n",
              "      <td>[1500, 1500]</td>\n",
              "      <td>[2048, 1500]</td>\n",
              "      <td>2251500.0</td>\n",
              "      <td>2250000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8_model.BatchNorm1d_8</th>\n",
              "      <td>[1500]</td>\n",
              "      <td>[2048, 1500]</td>\n",
              "      <td>3000.0</td>\n",
              "      <td>1500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9_model.GELU_9</th>\n",
              "      <td>-</td>\n",
              "      <td>[2048, 1500]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10_model.Dropout_10</th>\n",
              "      <td>-</td>\n",
              "      <td>[2048, 1500]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11_model.Linear_11</th>\n",
              "      <td>[1500, 1500]</td>\n",
              "      <td>[2048, 1500]</td>\n",
              "      <td>2251500.0</td>\n",
              "      <td>2250000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12_model.BatchNorm1d_12</th>\n",
              "      <td>[1500]</td>\n",
              "      <td>[2048, 1500]</td>\n",
              "      <td>3000.0</td>\n",
              "      <td>1500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13_model.GELU_13</th>\n",
              "      <td>-</td>\n",
              "      <td>[2048, 1500]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14_model.Linear_14</th>\n",
              "      <td>[1500, 1500]</td>\n",
              "      <td>[2048, 1500]</td>\n",
              "      <td>2251500.0</td>\n",
              "      <td>2250000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15_model.BatchNorm1d_15</th>\n",
              "      <td>[1500]</td>\n",
              "      <td>[2048, 1500]</td>\n",
              "      <td>3000.0</td>\n",
              "      <td>1500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16_model.GELU_16</th>\n",
              "      <td>-</td>\n",
              "      <td>[2048, 1500]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17_model.Dropout_17</th>\n",
              "      <td>-</td>\n",
              "      <td>[2048, 1500]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18_model.Linear_18</th>\n",
              "      <td>[1500, 1500]</td>\n",
              "      <td>[2048, 1500]</td>\n",
              "      <td>2251500.0</td>\n",
              "      <td>2250000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19_model.BatchNorm1d_19</th>\n",
              "      <td>[1500]</td>\n",
              "      <td>[2048, 1500]</td>\n",
              "      <td>3000.0</td>\n",
              "      <td>1500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20_model.GELU_20</th>\n",
              "      <td>-</td>\n",
              "      <td>[2048, 1500]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21_model.Linear_21</th>\n",
              "      <td>[1500, 750]</td>\n",
              "      <td>[2048, 750]</td>\n",
              "      <td>1125750.0</td>\n",
              "      <td>1125000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22_model.BatchNorm1d_22</th>\n",
              "      <td>[750]</td>\n",
              "      <td>[2048, 750]</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>750.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23_model.GELU_23</th>\n",
              "      <td>-</td>\n",
              "      <td>[2048, 750]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24_model.Dropout_24</th>\n",
              "      <td>-</td>\n",
              "      <td>[2048, 750]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25_model.Linear_25</th>\n",
              "      <td>[750, 750]</td>\n",
              "      <td>[2048, 750]</td>\n",
              "      <td>563250.0</td>\n",
              "      <td>562500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26_model.BatchNorm1d_26</th>\n",
              "      <td>[750]</td>\n",
              "      <td>[2048, 750]</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>750.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27_model.GELU_27</th>\n",
              "      <td>-</td>\n",
              "      <td>[2048, 750]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28_model.Dropout_28</th>\n",
              "      <td>-</td>\n",
              "      <td>[2048, 750]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29_model.Linear_29</th>\n",
              "      <td>[750, 750]</td>\n",
              "      <td>[2048, 750]</td>\n",
              "      <td>563250.0</td>\n",
              "      <td>562500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30_model.BatchNorm1d_30</th>\n",
              "      <td>[750]</td>\n",
              "      <td>[2048, 750]</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>750.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31_model.GELU_31</th>\n",
              "      <td>-</td>\n",
              "      <td>[2048, 750]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32_model.Dropout_32</th>\n",
              "      <td>-</td>\n",
              "      <td>[2048, 750]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33_model.Linear_33</th>\n",
              "      <td>[750, 750]</td>\n",
              "      <td>[2048, 750]</td>\n",
              "      <td>563250.0</td>\n",
              "      <td>562500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34_model.BatchNorm1d_34</th>\n",
              "      <td>[750]</td>\n",
              "      <td>[2048, 750]</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>750.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35_model.GELU_35</th>\n",
              "      <td>-</td>\n",
              "      <td>[2048, 750]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36_model.Dropout_36</th>\n",
              "      <td>-</td>\n",
              "      <td>[2048, 750]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37_model.Linear_37</th>\n",
              "      <td>[750, 750]</td>\n",
              "      <td>[2048, 750]</td>\n",
              "      <td>563250.0</td>\n",
              "      <td>562500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38_model.BatchNorm1d_38</th>\n",
              "      <td>[750]</td>\n",
              "      <td>[2048, 750]</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>750.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39_model.GELU_39</th>\n",
              "      <td>-</td>\n",
              "      <td>[2048, 750]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40_model.Dropout_40</th>\n",
              "      <td>-</td>\n",
              "      <td>[2048, 750]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41_model.Linear_41</th>\n",
              "      <td>[750, 750]</td>\n",
              "      <td>[2048, 750]</td>\n",
              "      <td>563250.0</td>\n",
              "      <td>562500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42_model.BatchNorm1d_42</th>\n",
              "      <td>[750]</td>\n",
              "      <td>[2048, 750]</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>750.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43_model.GELU_43</th>\n",
              "      <td>-</td>\n",
              "      <td>[2048, 750]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44_model.Dropout_44</th>\n",
              "      <td>-</td>\n",
              "      <td>[2048, 750]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45_model.Linear_45</th>\n",
              "      <td>[750, 750]</td>\n",
              "      <td>[2048, 750]</td>\n",
              "      <td>563250.0</td>\n",
              "      <td>562500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46_model.BatchNorm1d_46</th>\n",
              "      <td>[750]</td>\n",
              "      <td>[2048, 750]</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>750.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47_model.GELU_47</th>\n",
              "      <td>-</td>\n",
              "      <td>[2048, 750]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48_model.Dropout_48</th>\n",
              "      <td>-</td>\n",
              "      <td>[2048, 750]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49_model.Linear_49</th>\n",
              "      <td>[750, 656]</td>\n",
              "      <td>[2048, 656]</td>\n",
              "      <td>492656.0</td>\n",
              "      <td>492000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50_model.BatchNorm1d_50</th>\n",
              "      <td>[656]</td>\n",
              "      <td>[2048, 656]</td>\n",
              "      <td>1312.0</td>\n",
              "      <td>656.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51_model.GELU_51</th>\n",
              "      <td>-</td>\n",
              "      <td>[2048, 656]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52_model.Dropout_52</th>\n",
              "      <td>-</td>\n",
              "      <td>[2048, 656]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53_model.Linear_53</th>\n",
              "      <td>[656, 42]</td>\n",
              "      <td>[2048, 42]</td>\n",
              "      <td>27594.0</td>\n",
              "      <td>27552.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b409e858-6a28-47df-8592-c2874fa9968a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b409e858-6a28-47df-8592-c2874fa9968a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b409e858-6a28-47df-8592-c2874fa9968a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "INPUT_SIZE  = (2*config['context'] + 1) * 27 # Why is this the case?\n",
        "model       = Network(INPUT_SIZE, len(train_data.phonemes)).to(device)\n",
        "model.apply(initialize)\n",
        "summary(model, frames.to(device))\n",
        "# Check number of parameters of your network\n",
        "# Remember, you are limited to 20 million parameters for HW1 (including ensembles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UROGEVJevKD-"
      },
      "outputs": [],
      "source": [
        "from contextlib import ExitStack\n",
        "criterion = torch.nn.CrossEntropyLoss() # Defining Loss function. \n",
        "# We use CE because the task is multi-class classification \n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr= config['init_lr'], weight_decay= config['weight_decay']) #Defining Optimizer\n",
        "# Recommended : Define Scheduler for Learning Rate, \n",
        "\n",
        "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= config['step_size'], gamma= config['gamma']) #Defining StepLR Scheduler\n",
        "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max= config['T_max'], eta_min= config['eta_min'])\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode= 'min', factor= config['factor'], patience= 5, threshold= 1e-4)\n",
        "# including but not limited to StepLR, MultiStepLR, CosineAnnealingLR, ReduceLROnPlateau, etc. \n",
        "# You can refer to Pytorch documentation for more information on how to use them.\n",
        "\n",
        "# Is your training time very high? \n",
        "# Look into mixed precision training if your GPU (Tesla T4, V100, etc) can make use of it \n",
        "# Refer - https://pytorch.org/docs/stable/notes/amp_examples.html\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBwunYpyugFg"
      },
      "source": [
        "# Training and Validation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JgeNhx4x2-P"
      },
      "source": [
        "This section covers the training, and validation functions for each epoch of running your experiment with a given model architecture. The code has been provided to you, but we recommend going through the comments to understand the workflow to enable you to write these loops for future HWs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XblOHEVtKab2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cacf1bba-265e-481f-c897-e68b745b5fcf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "914"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wjPz7DHqKcL"
      },
      "outputs": [],
      "source": [
        "from torch._C import dtype\n",
        "def train(model, dataloader, optimizer, criterion):\n",
        "\n",
        "    model.train()\n",
        "    tloss, tacc = 0, 0 # Monitoring loss and accuracy\n",
        "    batch_bar   = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train')\n",
        "\n",
        "    for i, (frames, phonemes) in enumerate(dataloader):\n",
        "        \n",
        "        ### Initialize Gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        ### Move Data to Device (Ideally GPU)\n",
        "        frames      = frames.to(device)\n",
        "        phonemes    = phonemes.to(device)\n",
        "\n",
        "        # with torch.cuda.amp.autocast('cuda'):\n",
        "          ### Forward Propagation\n",
        "        logits  = model(frames)\n",
        "\n",
        "          ### Loss Calculation\n",
        "        loss    = criterion(logits, phonemes)\n",
        "\n",
        "        ### Backward Propagation\n",
        "        loss.backward() \n",
        "        # scaler.scale(loss).backward()\n",
        "        # scaler.step(optimizer)\n",
        "        # scaler.update()\n",
        "\n",
        "        ### Gradient Descent\n",
        "        optimizer.step()       \n",
        "        \n",
        "\n",
        "        tloss   += loss.item()\n",
        "        tacc    += torch.sum(torch.argmax(logits, dim= 1) == phonemes).item()/logits.shape[0]\n",
        "\n",
        "        batch_bar.set_postfix(loss=\"{:.04f}\".format(float(tloss / (i + 1))), \n",
        "                              acc=\"{:.04f}%\".format(float(tacc*100 / (i + 1))))\n",
        "        batch_bar.update()\n",
        "\n",
        "        ### Release memory\n",
        "        del frames, phonemes, logits\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # ### Mixed Precision\n",
        "\n",
        "        # with autocast(device_type='cuda', dtype= torch.float16):\n",
        "        #   output = model(input)\n",
        "        #   loss = loss_fn(output, target)\n",
        "        \n",
        "        # scaler.scale(loss).backward()\n",
        "        # scaler.step()\n",
        "        # scaler.update()\n",
        "  \n",
        "    \n",
        "    batch_bar.close()\n",
        "    tloss   /= len(train_loader)\n",
        "    tacc    /= len(train_loader)\n",
        "    scheduler.step(tloss) #adding scheduler plateau function\n",
        "\n",
        "    return tloss, tacc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5npQNFH315V"
      },
      "outputs": [],
      "source": [
        "def eval(model, dataloader):\n",
        "\n",
        "    model.eval() # set model in evaluation mode\n",
        "    vloss, vacc = 0, 0 # Monitoring loss and accuracy\n",
        "    batch_bar   = tqdm(total=len(val_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n",
        "\n",
        "    for i, (frames, phonemes) in enumerate(dataloader):\n",
        "\n",
        "        ### Move data to device (ideally GPU)\n",
        "        frames      = frames.to(device)\n",
        "        phonemes    = phonemes.to(device)\n",
        "\n",
        "        # makes sure that there are no gradients computed as we are not training the model now\n",
        "        with torch.inference_mode(): \n",
        "            ### Forward Propagation\n",
        "            logits  = model(frames)\n",
        "            ### Loss Calculation\n",
        "            loss    = criterion(logits, phonemes)\n",
        "\n",
        "        vloss   += loss.item()\n",
        "        vacc    += torch.sum(torch.argmax(logits, dim= 1) == phonemes).item()/logits.shape[0]\n",
        "        \n",
        "        # Do you think we need loss.backward() and optimizer.step() here?\n",
        "\n",
        "        batch_bar.set_postfix(loss=\"{:.04f}\".format(float(vloss / (i + 1))), \n",
        "                              acc=\"{:.04f}%\".format(float(vacc*100 / (i + 1))))\n",
        "        batch_bar.update()\n",
        "    \n",
        "        ### Release memory\n",
        "        del frames, phonemes, logits\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    batch_bar.close()\n",
        "    vloss   /= len(val_loader)\n",
        "    vacc    /= len(val_loader)\n",
        "\n",
        "    return vloss, vacc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMd_XxPku5qp"
      },
      "source": [
        "# Weights and Biases Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjIbhR1wwbgI"
      },
      "source": [
        "This section is to enable logging metrics and files with Weights and Biases. Please refer to wandb documentationa and recitation 0 that covers the use of weights and biases for logging, hyperparameter tuning and monitoring your runs for your homeworks. Using this tool makes it very easy to show results when submitting your code and models for homeworks, and also extremely useful for study groups to organize and run ablations under a single team in wandb. \n",
        "\n",
        "We have written code for you to make use of it out of the box, so that you start using wandb for all your HWs from the beginning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCDYx5VEu6qI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f92d8a5e-9fa4-484b-a2ae-2e64ce6f4b0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "wandb.login(key=\"f303efa63722be981833b9f7e8dd7bb0efd47e1f\") #API Key is in your wandb account, under settings (wandb.ai/settings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvUnYd3Bw2up",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "68b3f9ed-6838-46d8-a912-9ee9480d07cd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230217_144923-jfc42chs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Resuming run <strong><a href='https://wandb.ai/idls23/hw1p2/runs/jfc42chs' target=\"_blank\">nchinnal-run25-460</a></strong> to <a href='https://wandb.ai/idls23/hw1p2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/idls23/hw1p2' target=\"_blank\">https://wandb.ai/idls23/hw1p2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/idls23/hw1p2/runs/jfc42chs' target=\"_blank\">https://wandb.ai/idls23/hw1p2/runs/jfc42chs</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Create your wandb run\n",
        "run = wandb.init(\n",
        "    name    = \"nchinnal-run25-460\", ### Wandb creates random run names if you skip this field, we recommend you give useful names\n",
        "    # reinit  = True, ### Allows reinitalizing runs when you re-run this cell\n",
        "    id     = \"jfc42chs\", ### Insert specific run id here if you want to resume a previous run\n",
        "    resume = \"must\", ### You need this to resume previous runs, but comment out reinit = True when using this\n",
        "    project = \"hw1p2\", ### Project should be created in your wandb account \n",
        "    config  = config ### Wandb Config for your run\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wft15E_IxYFi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6087a2cc-102d-4fad-a9b8-45df086f6497"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/wandb/run-20230217_034508-jfc42chs/files/model_arch.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "### Save your model architecture as a string with str(model) \n",
        "model_arch  = str(model)\n",
        "\n",
        "### Save it in a txt file \n",
        "arch_file   = open(\"model_arch.txt\", \"w\")\n",
        "file_write  = arch_file.write(model_arch)\n",
        "arch_file.close()\n",
        "\n",
        "### log it in your wandb run with wandb.save()\n",
        "wandb.save('model_arch.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nclx_04fu7Dd"
      },
      "source": [
        "# Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdLMWfEpyGOB"
      },
      "source": [
        "Now, it is time to finally run your ablations! Have fun!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MG4F77Nm0Am9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872,
          "referenced_widgets": [
            "76def4d5374c4dea82d6adb4d53f02da",
            "d7de430e329d437ca197ce025b2945f2",
            "aecadfafea104f44b3a056acd81ec014",
            "51288aaf4090498483b84d96e16f258d",
            "4e38f33242194d5e828fb2fbf099cf82",
            "d753406aa2584a85bccb82089a8e2f88",
            "21924c0993be47b2a3a795fde5c6e44c",
            "c6f45d25783e4637b99f8e171def0f1d",
            "7965c12ab2cf42098a30bbd18617fb3e",
            "21c441167103431fa5477b8b951c5239",
            "d7e659d57daa4cb0a6bf5efd549d7668",
            "10f86d92237a43bf88d1c17b79847ba5",
            "77412bbd4b6944729b1035d13987e2a0",
            "0ee3c0caf065453f91dce29a7ab00479",
            "dafc7e5702b4494e9407e3c6accf6cf0",
            "e77f1c64c9ac4fe38617bbbab671fee3",
            "4ac8641ce9734923bf44550eff501186",
            "846de906ad2d4209be083b7ead1e3d53",
            "3b25cde51b0a40aa996db44dccdf22b6",
            "3faca028a7c94b7ca0cc883a6a035572",
            "4b1a598ce0cc45bc8691ee959e9f2a53",
            "2cdf92154f624b518463791d3c8e1728",
            "6844d012ed204519b01ee3c2340f609e",
            "f8dfc1599697457bb1cc3979fd9ed604",
            "25ea826addd7429ba6e89af15e836f03",
            "152ede8f0b304a50ba36feea68ebeefc",
            "77348c7660274d35b6acf953c6083204",
            "6c5dd2e30a5f471598c3e10b86957b90",
            "741b88d6481b4383907f23755c5683dd",
            "793c0143e20c49b18016d13b4aa1fbf0",
            "de5334696e70481a9c1d11a9e60138f3",
            "fbd7dca66f3840f4882e79a187a96c67",
            "a970cce56fce420aa5d4a083d450a4a7",
            "b03b717602d1422dba2e9a793679f61d",
            "b21203913b3740638374b0775f8ae6b1",
            "3eaa716949c643da8551a2104c81ef04",
            "af14c9e12b8f4d338a1e498fff67ecb0",
            "d6aec14b76da48f3b1dc94c9242ae76e",
            "a50fd08e6f3244e0902f6f33ba76e071",
            "d40411414a8b4b99ae9fc267daa8c035",
            "1bdf7defcfab42438d9fec5bb1b6b024",
            "efe7a16801614d25ad690d886bc6831d",
            "3d00a81635b7429cb58cfdc02c586b01",
            "ed4098eec2b346098e5fe773501207bf",
            "5c7321dcfbec4f7c89ed92cbb39ec2ae",
            "4ac3b00b787640819d28803c2bf4d856",
            "9a25059284a94605a9e0695c78f94c77",
            "872aa85e224f4d0da649a56cd44b74d2"
          ]
        },
        "outputId": "4a08b1e4-2013-4116-af17-f8a1e80df11e"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76def4d5374c4dea82d6adb4d53f02da",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/82263 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10f86d92237a43bf88d1c17b79847ba5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/942 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 87.6180%\tTrain Loss 0.3556\t Learning Rate 0.0010000\n",
            "\tVal Acc 89.2162%\tVal Loss 0.2988\n",
            "\n",
            "Epoch 2/5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77412bbd4b6944729b1035d13987e2a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/82263 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ee3c0caf065453f91dce29a7ab00479",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/942 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 87.6674%\tTrain Loss 0.3538\t Learning Rate 0.0010000\n",
            "\tVal Acc 89.3735%\tVal Loss 0.2955\n",
            "\n",
            "Epoch 3/5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dafc7e5702b4494e9407e3c6accf6cf0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/82263 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e77f1c64c9ac4fe38617bbbab671fee3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/942 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 87.7190%\tTrain Loss 0.3522\t Learning Rate 0.0010000\n",
            "\tVal Acc 89.2753%\tVal Loss 0.2980\n",
            "\n",
            "Epoch 4/5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ac8641ce9734923bf44550eff501186",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/82263 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c5dd2e30a5f471598c3e10b86957b90",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/942 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 87.7595%\tTrain Loss 0.3508\t Learning Rate 0.0010000\n",
            "\tVal Acc 89.4303%\tVal Loss 0.2936\n",
            "\n",
            "Epoch 5/5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "741b88d6481b4383907f23755c5683dd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/82263 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Val:   0%|          | 0/942 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "793c0143e20c49b18016d13b4aa1fbf0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Acc 87.7950%\tTrain Loss 0.3496\t Learning Rate 0.0010000\n",
            "\tVal Acc 89.4181%\tVal Loss 0.2931\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1bdf7defcfab42438d9fec5bb1b6b024"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▇█</td></tr><tr><td>train_loss</td><td>█▆▄▂▁</td></tr><tr><td>val_acc</td><td>▁▆▃██</td></tr><tr><td>valid_loss</td><td>█▄▇▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>0.001</td></tr><tr><td>train_acc</td><td>87.79504</td></tr><tr><td>train_loss</td><td>0.34957</td></tr><tr><td>val_acc</td><td>89.41815</td></tr><tr><td>valid_loss</td><td>0.29306</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">nchinnal-run25-460</strong> at: <a href='https://wandb.ai/idls23/hw1p2/runs/jfc42chs' target=\"_blank\">https://wandb.ai/idls23/hw1p2/runs/jfc42chs</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230217_034508-jfc42chs/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Iterate over number of epochs to train and evaluate your model\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "wandb.watch(model, log=\"all\")\n",
        "\n",
        "for epoch in range(config['epochs']):\n",
        "\n",
        "    print(\"\\nEpoch {}/{}\".format(epoch+1, config['epochs']))\n",
        "\n",
        "    curr_lr                 = float(optimizer.param_groups[0]['lr'])\n",
        "    train_loss, train_acc   = train(model, train_loader, optimizer, criterion)\n",
        "    val_loss, val_acc       = eval(model, val_loader)\n",
        "\n",
        "    print(\"\\tTrain Acc {:.04f}%\\tTrain Loss {:.04f}\\t Learning Rate {:.07f}\".format(train_acc*100, train_loss, curr_lr))\n",
        "    print(\"\\tVal Acc {:.04f}%\\tVal Loss {:.04f}\".format(val_acc*100, val_loss))\n",
        "\n",
        "    ### Log metrics at each epoch in your run \n",
        "    # Optionally, you can log at each batch inside train/eval functions \n",
        "    # (explore wandb documentation/wandb recitation)\n",
        "    wandb.log({'train_acc': train_acc*100, 'train_loss': train_loss, \n",
        "               'val_acc': val_acc*100, 'valid_loss': val_loss, 'lr': curr_lr})\n",
        "\n",
        "    ### Highly Recommended: Save checkpoint in drive and/or wandb if accuracy is better than your current best\n",
        "# if best_acc < val_acc:\n",
        "    # best_acc = val_acc\n",
        "save_path = \"best_model_{0}_{1}_{2}.pth\".format(config['init_lr'],config['batch_size'],config['context'])\n",
        "torch.save({'model_state_dict':model.state_dict(),\n",
        "            'optimizer_state_dict':optimizer.state_dict()},\n",
        "            '/content/'+save_path)\n",
        "### Finish your wandb run\n",
        "run.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kXwf5YUo_4A"
      },
      "source": [
        "# Testing and submission to Kaggle\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI1hSFYLpJvH"
      },
      "source": [
        "Before we get to the following code, make sure to see the format of submission given in *sample_submission.csv*. Once you have done so, it is time to fill the following function to complete your inference on test data. Refer the eval function from previous cells to get an idea of how to go about completing this function."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_acc = val_acc"
      ],
      "metadata": {
        "id": "r-5BW-uX7oE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-SU9fZ3xHtk"
      },
      "outputs": [],
      "source": [
        "def test(model, test_loader):\n",
        "    ### What you call for model to perform inference?\n",
        "    model.eval() # TODO train or eval?\n",
        "\n",
        "    ### List to store predicted phonemes of test data\n",
        "    test_predictions = []\n",
        "\n",
        "    ### Which mode do you need to avoid gradients?\n",
        "    with torch.inference_mode(): # TODO\n",
        "\n",
        "        for i, mfccs in enumerate(tqdm(test_loader)):\n",
        "\n",
        "            mfccs   = mfccs.to(device)             \n",
        "            \n",
        "            logits  = model(mfccs)\n",
        "\n",
        "            ### Get most likely predicted phoneme with argmax\n",
        "            predicted_phonemes = torch.argmax(logits, dim=1)\n",
        "\n",
        "            ### How do you store predicted_phonemes with test_predictions? Hint, look at eval \n",
        "            # TODO\n",
        "            test_predictions.extend(predicted_phonemes.tolist())\n",
        "\n",
        "    return test_predictions\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Best Model ##\n",
        "check_point = torch.load('/content/'+save_path)\n",
        "model.load_state_dict(check_point['model_state_dict'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Vkmj_ayWgBo",
        "outputId": "188d61bf-de61-4aaf-cff1-5544dd1f3159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wG9v6Xmxu7wp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "607efd8255a64147a9aabb53f31016b1",
            "866f6cacf8cd4e72b441981455f2e006",
            "4632006202244d05829a47a93e7c77ce",
            "c3d9f0fbd1b5417b9ef545b166cc3953",
            "fd39358d7c984edf941330cce0ae965d",
            "692a46dc6cec4f8e84634c89a1620e7e",
            "fdd816c2910946c6b12d0a0fab1b6480",
            "404b7dc74409472c925d6a1d46f720b0",
            "90bc1b80f8b24cf59b70db50cef98719",
            "b90d581ecf5c4b6bafba8d22de12b526",
            "81e7f49a5f6a4ef2877e4ad551d2e040"
          ]
        },
        "outputId": "0b6eff56-0a70-46fc-b226-52837f461e8e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/945 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "607efd8255a64147a9aabb53f31016b1"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "predictions = test(model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [PHONEMES[x] for x in predictions]"
      ],
      "metadata": {
        "id": "j3ntHpQsw2gO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YQMhA_lxTSF",
        "outputId": "61c3e1a6-ddc8-4878-c094-19110f7e2e85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1934138"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZE1hRnvf0bFz"
      },
      "outputs": [],
      "source": [
        "### Create CSV file with predictions\n",
        "with open(\"./submission.csv\", \"w+\") as f:\n",
        "    f.write(\"id,label\\n\")\n",
        "    for i in range(len(predictions)):\n",
        "        f.write(\"{},{}\\n\".format(i, predictions[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjcammuCxMKN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a14c3042-37b3-4101-cb4d-6a3860ead3ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.8)\n",
            "100% 19.3M/19.3M [00:00<00:00, 30.8MB/s]\n",
            "Successfully submitted to Frame-Level Speech Recognition"
          ]
        }
      ],
      "source": [
        "### Submit to kaggle competition using kaggle API (Uncomment below to use)\n",
        "!kaggle competitions submit -c 11-785-s23-hw1p2 -f ./submission.csv -m \"Test Submission\"\n",
        "\n",
        "### However, its always safer to download the csv file and then upload to kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yLRDGkQ-rRQE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.16 ('IDL')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "de32b131b9090cf891ded5cf62d64adc7e3be0bc684cf6f58cdc7cd1b4ee35b9"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "76def4d5374c4dea82d6adb4d53f02da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7de430e329d437ca197ce025b2945f2",
              "IPY_MODEL_aecadfafea104f44b3a056acd81ec014",
              "IPY_MODEL_51288aaf4090498483b84d96e16f258d"
            ],
            "layout": "IPY_MODEL_4e38f33242194d5e828fb2fbf099cf82"
          }
        },
        "d7de430e329d437ca197ce025b2945f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d753406aa2584a85bccb82089a8e2f88",
            "placeholder": "​",
            "style": "IPY_MODEL_21924c0993be47b2a3a795fde5c6e44c",
            "value": "Train:  58%"
          }
        },
        "aecadfafea104f44b3a056acd81ec014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6f45d25783e4637b99f8e171def0f1d",
            "max": 82263,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7965c12ab2cf42098a30bbd18617fb3e",
            "value": 77691
          }
        },
        "51288aaf4090498483b84d96e16f258d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21c441167103431fa5477b8b951c5239",
            "placeholder": "​",
            "style": "IPY_MODEL_d7e659d57daa4cb0a6bf5efd549d7668",
            "value": " 77691/82263 [2:02:31&lt;07:21, 10.35it/s, acc=87.6187%, loss=0.3555]"
          }
        },
        "4e38f33242194d5e828fb2fbf099cf82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "d753406aa2584a85bccb82089a8e2f88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21924c0993be47b2a3a795fde5c6e44c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6f45d25783e4637b99f8e171def0f1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7965c12ab2cf42098a30bbd18617fb3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21c441167103431fa5477b8b951c5239": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7e659d57daa4cb0a6bf5efd549d7668": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ac8641ce9734923bf44550eff501186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_846de906ad2d4209be083b7ead1e3d53",
              "IPY_MODEL_3b25cde51b0a40aa996db44dccdf22b6",
              "IPY_MODEL_3faca028a7c94b7ca0cc883a6a035572"
            ],
            "layout": "IPY_MODEL_4b1a598ce0cc45bc8691ee959e9f2a53"
          }
        },
        "846de906ad2d4209be083b7ead1e3d53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cdf92154f624b518463791d3c8e1728",
            "placeholder": "​",
            "style": "IPY_MODEL_6844d012ed204519b01ee3c2340f609e",
            "value": "Train:  81%"
          }
        },
        "3b25cde51b0a40aa996db44dccdf22b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8dfc1599697457bb1cc3979fd9ed604",
            "max": 82263,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25ea826addd7429ba6e89af15e836f03",
            "value": 77971
          }
        },
        "3faca028a7c94b7ca0cc883a6a035572": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_152ede8f0b304a50ba36feea68ebeefc",
            "placeholder": "​",
            "style": "IPY_MODEL_77348c7660274d35b6acf953c6083204",
            "value": " 77971/82263 [2:02:35&lt;06:42, 10.67it/s, acc=87.7617%, loss=0.3507]"
          }
        },
        "4b1a598ce0cc45bc8691ee959e9f2a53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "2cdf92154f624b518463791d3c8e1728": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6844d012ed204519b01ee3c2340f609e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8dfc1599697457bb1cc3979fd9ed604": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25ea826addd7429ba6e89af15e836f03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "152ede8f0b304a50ba36feea68ebeefc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77348c7660274d35b6acf953c6083204": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "793c0143e20c49b18016d13b4aa1fbf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de5334696e70481a9c1d11a9e60138f3",
              "IPY_MODEL_fbd7dca66f3840f4882e79a187a96c67",
              "IPY_MODEL_a970cce56fce420aa5d4a083d450a4a7"
            ],
            "layout": "IPY_MODEL_b03b717602d1422dba2e9a793679f61d"
          }
        },
        "de5334696e70481a9c1d11a9e60138f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b21203913b3740638374b0775f8ae6b1",
            "placeholder": "​",
            "style": "IPY_MODEL_3eaa716949c643da8551a2104c81ef04",
            "value": "Val: 100%"
          }
        },
        "fbd7dca66f3840f4882e79a187a96c67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af14c9e12b8f4d338a1e498fff67ecb0",
            "max": 942,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6aec14b76da48f3b1dc94c9242ae76e",
            "value": 942
          }
        },
        "a970cce56fce420aa5d4a083d450a4a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a50fd08e6f3244e0902f6f33ba76e071",
            "placeholder": "​",
            "style": "IPY_MODEL_d40411414a8b4b99ae9fc267daa8c035",
            "value": " 941/942 [00:29&lt;00:00, 27.14it/s, acc=89.4181%, loss=0.2931]"
          }
        },
        "b03b717602d1422dba2e9a793679f61d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "b21203913b3740638374b0775f8ae6b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3eaa716949c643da8551a2104c81ef04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af14c9e12b8f4d338a1e498fff67ecb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6aec14b76da48f3b1dc94c9242ae76e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a50fd08e6f3244e0902f6f33ba76e071": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d40411414a8b4b99ae9fc267daa8c035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bdf7defcfab42438d9fec5bb1b6b024": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_efe7a16801614d25ad690d886bc6831d",
              "IPY_MODEL_3d00a81635b7429cb58cfdc02c586b01"
            ],
            "layout": "IPY_MODEL_ed4098eec2b346098e5fe773501207bf"
          }
        },
        "efe7a16801614d25ad690d886bc6831d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c7321dcfbec4f7c89ed92cbb39ec2ae",
            "placeholder": "​",
            "style": "IPY_MODEL_4ac3b00b787640819d28803c2bf4d856",
            "value": "0.638 MB of 0.638 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "3d00a81635b7429cb58cfdc02c586b01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a25059284a94605a9e0695c78f94c77",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_872aa85e224f4d0da649a56cd44b74d2",
            "value": 1
          }
        },
        "ed4098eec2b346098e5fe773501207bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c7321dcfbec4f7c89ed92cbb39ec2ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ac3b00b787640819d28803c2bf4d856": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a25059284a94605a9e0695c78f94c77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "872aa85e224f4d0da649a56cd44b74d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "607efd8255a64147a9aabb53f31016b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_866f6cacf8cd4e72b441981455f2e006",
              "IPY_MODEL_4632006202244d05829a47a93e7c77ce",
              "IPY_MODEL_c3d9f0fbd1b5417b9ef545b166cc3953"
            ],
            "layout": "IPY_MODEL_fd39358d7c984edf941330cce0ae965d"
          }
        },
        "866f6cacf8cd4e72b441981455f2e006": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_692a46dc6cec4f8e84634c89a1620e7e",
            "placeholder": "​",
            "style": "IPY_MODEL_fdd816c2910946c6b12d0a0fab1b6480",
            "value": "100%"
          }
        },
        "4632006202244d05829a47a93e7c77ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_404b7dc74409472c925d6a1d46f720b0",
            "max": 945,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90bc1b80f8b24cf59b70db50cef98719",
            "value": 945
          }
        },
        "c3d9f0fbd1b5417b9ef545b166cc3953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b90d581ecf5c4b6bafba8d22de12b526",
            "placeholder": "​",
            "style": "IPY_MODEL_81e7f49a5f6a4ef2877e4ad551d2e040",
            "value": " 945/945 [00:25&lt;00:00, 39.54it/s]"
          }
        },
        "fd39358d7c984edf941330cce0ae965d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "692a46dc6cec4f8e84634c89a1620e7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdd816c2910946c6b12d0a0fab1b6480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "404b7dc74409472c925d6a1d46f720b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90bc1b80f8b24cf59b70db50cef98719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b90d581ecf5c4b6bafba8d22de12b526": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81e7f49a5f6a4ef2877e4ad551d2e040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}